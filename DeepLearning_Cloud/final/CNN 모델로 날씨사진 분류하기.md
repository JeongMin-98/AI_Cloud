# ë”¥ëŸ¬ë‹/í´ë¼ìš°ë“œ ê¸°ë§ê³¼ì œ - ì‚¬ì§„ íŒŒì¼ ë¶„ë¥˜í•˜ê¸°

<aside>
ğŸ’¡ **ê¸°ë§ ê³¼ì œ ëª©í‘œ:** 1,125ê°œì˜ ë‚ ì”¨ ì‚¬ì§„ì„ ë¶„ë¥˜í•˜ëŠ” CNN ëª¨ë¸ì„ ë§Œë“¤ê³  ê·¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©í–¥ì„ ì œì‹œ

</aside>

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled.png)

# ğŸ‘€Â CNN ì´ë€?

> CNN ëª¨ë¸ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ê¸° ìš©ì´í•œ ëª¨ë¸ì´ë‹¤. 
ì´ë¯¸ì§€ë¥¼ Conv ì—°ì‚°ê³¼ Pooling layerë¡œ ê³„ì¸µí™”í•˜ì—¬ ì—°ì‚°ì‹œí‚¤ê³  ì¶œë ¥ì¸µì— Fully connectedí•˜ì—¬ Affineí•œ ì‹ ê²½ë§ì´ë‹¤. 
ë‹¤ë¥¸ Fully connected layerì™€ëŠ” ë‹¤ë¥¸ ì ìœ¼ë¡œ Convì—°ì‚°ê³¼ Pooling layerë¥¼ ì‚¬ìš©í•œë‹¤.
> 

---

# ğŸ’­Â ì‚¬ìš© ê°œë…

> Convolution ì—°ì‚°
pooling
Image Augmentation
Data Load ì„±ëŠ¥ ê°œì„ 
Dropout
> 

---

# ğŸ›«Â í”Œëœ

> MLops ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì„¤ê³„, í”¼ë“œë°±í•  ì˜ˆì •ì´ë‹¤. 
ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œëŠ” Training Errorì™€ Test Errorì˜ ì°¨ì´ê°€ ê°€ì¥ ì ìœ¼ë©° Test Errorê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸ì„ ì„ íƒí•  ê²ƒì´ë‹¤. 
ëª¨ë¸ì˜ ì„±ëŠ¥ ê°œì„ ì€ Image Augmentationìœ¼ë¡œ ë°ì´í„° í‘œë³¸ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ê³ , Dropoutí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•œë‹¤.
> 

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •(ê°€ìƒí™˜ê²½ ì„¤ì •)

> python â‰¥ 3.7
numpy â‰¥ 1.23
tensorflow â‰¥ 2 (gpu ë²„ì „)
> 

# ë°ì´í„° ì „ì²˜ë¦¬

ê³¼ì œì— ì£¼ì–´ì§„ ì´ë¯¸ì§€ì˜ ê°œìˆ˜ëŠ” 1,125ê°œì´ë‹¤. í•´ë‹¹ ëª¨ë¸ì€ ê° labelì— ë”°ë¼ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•œë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ì˜ labelì¸ cloudy, rain, shine, sunriseë¡œ í•˜ìœ„ ë””ë ‰í† ë¦¬ë¡œ ë‚˜ëˆ„ì–´ ì‚¬ì§„ë“¤ì„ ì •ë¦¬í•œë‹¤. 

ë‹¤ìŒê³¼ ê°™ì´ ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¥¼ ë§Œë“ ë‹¤.

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%201.png)

ì´ë¯¸ì§€ì˜ ì…ë ¥ ì‚¬ì´ì¦ˆëŠ” 180 * 180ë¡œ ì •í•˜ì˜€ë‹¤. 

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%202.png)

- ì´ APIëŠ” ë””ë ‰í† ë¦¬ì— í•˜ìœ„ ë””ë ‰í† ë¦¬ì— class_a, class_bê°€ ìˆë‹¤ë©´, í•˜ìœ„ë””ë ‰í† ë¦¬ê°€ labelì´ ë˜ë©°, ê°ê° class_a, class_bì— 0, 1ë¡œ ëŒ€ì‘ë˜ëŠ” labelsì„ ê°€ì§€ëŠ” tr.data.datasetì„ ë°˜í™˜í•œë‹¤.
- subset ì¸ìëŠ” í•´ë‹¹ ë°ì´í„°ê°€ validation dataì¸ì§€, training dataì¸ì§€ ë‚˜ëˆˆë‹¤.
- label_mode ì¸ìëŠ” í•´ë‹¹ ë°ì´í„°ì˜ labelë¥¼ int, catergorical, binary(ì´ì§„ë¶„ë¥˜)ì¸ì§€ ê²°ì •í•œë‹¤.
- ì´ apië¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì´ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ train:testë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì— ì‚¬ìš©í•œë‹¤.

ì½”ë“œ ë¶€ë¶„ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ì§œ train:test(validation)ì„ 7:3 ë¹„ìœ¨ë¡œ ë‚˜ëˆˆë‹¤. 

```python
# batch_size ì²˜ìŒì€ 32ë¡œ ì •í•¨
batch_size = 32
img_height = 180
img_width = 180

# Data_dirì— ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ tf.data.datasetìœ¼ë¡œ í˜•ì„±
train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    batch_size=batch_size,
    image_size=(img_height,img_width),
    seed=123,
    validation_split=0.3,
    subset='training',
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    batch_size=batch_size,
    image_size=(img_height,img_width),
    seed=123,
    validation_split=0.3,
    subset='validation',
)
```

# ëª¨ë¸ êµ¬ì„±

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%203.png)

1. ì´ë¯¸ì§€ê°€ ì…ë ¥ë˜ê¸° ì „ ëª¨ë“  ë°ì´í„°ëŠ” Rescalling ê³¼ì •ì„ ê±°ì¹œë‹¤. 
2. ì²˜ìŒ ëª¨ë¸ í•™ìŠµì˜ epoch ìˆ˜ëŠ” 50ìœ¼ë¡œ ì§€ì •
3. ëª¨ë¸ ê²°ê³¼ì˜ ì •í™•ë„ì™€ í•™ìŠµ ê³¡ì„ ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%204.png)

1. í•´ë‹¹ ê·¸ë˜í”„ë¥¼ í™•ì¸í•œ ê²°ê³¼ epochìˆ˜ê°€ 50ë²ˆì€ ë„ˆë¬´ ë§ì€ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆë‹¤.
2. ìœ ì˜ë¯¸í•œ í•™ìŠµ ê·¸ë˜í”„ë¥¼ ê°€ì§€ê¸° ìœ„í•´ì„œëŠ” early stoppingì„ í•˜ì—¬ epochìˆ˜ë¥¼ 20ë²ˆìœ¼ë¡œ ì§€ì •í•˜ê¸°ë¡œ í•˜ì˜€ë‹¤.
- í•´ë‹¹ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” ë§¤ìš° ë†’ì€ ìˆ˜ì¤€ì— ê·¼ì‚¬í•˜ë‚˜ ì´ ê¸°ë³¸ ëª¨ë¸ì€ í•™ìŠµ ëª¨ë¸ê³¼ ê²€ì¦ ëª¨ë¸ì˜ ì •í™•ë„ ì°¨ì´ê°€ í™•ì—°í•˜ê²Œ ë²Œì–´ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ê³¼ëŒ€ì í•© ì§•í›„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— dropoutê³¼ data augumentationì„ ì ìš©í•˜ê¸°ë¡œ í•˜ì˜€ë‹¤.

# ëª¨ë¸ ìµœì í™”

## ë°ì´í„° ì¦ê°•

<aside>
ğŸ’¡ ë°ì´í„° ì¦ê°• (Data Augmetation)ì€ ì´ë¯¸ì§€ë¥¼ íšŒì „, ë°˜ì „, í™•ëŒ€, ì¶•ì†Œ, ìƒ‰ì¡° ë³€í™˜ë“± ì—¬ëŸ¬ê°€ì§€ ì´ë¯¸ì§€ ë³€í™˜ì„ í†µí•´ ê¸°ì¡´ ë°ì´í„°ë³´ë‹¤ ë§ì€ ë°ì´í„°ì˜ ì–‘ì„ í™•ë³´í•˜ì—¬ ëª¨ë¸ì˜ ê³¼ëŒ€ì í•©ì„ ë°©ì§€í•˜ë„ë¡ í•œë‹¤

</aside>

ë°ì´í„° ì¦ê°•ì„ í•˜ê¸°ìœ„í•´ì„œ input layer ë‹¨ê³„ ì´ì „ì— ë‹¤ìŒê³¼ ì½”ë“œë¥¼ ì‚½ì…í•œë‹¤. 

```python
data_augmentation = tf.keras.Sequential(
    [
        layers.experimental.preprocessing.RandomFlip('horizontal',
                                                     input_shape=(img_height, img_width, 3)),
        layers.experimental.preprocessing.RandomFlip('vertical'),
        layers.experimental.preprocessing.RandomRotation(0.2),
        layers.experimental.preprocessing.RandomZoom(0.2)
    ]
)
```

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%205.png)

ë°ì´í„° ì¦ê°• ê¸°ë²•ì„ ì‚¬ìš©í•˜ê²Œë˜ë©´ ê¸°ì¡´ì— ê°€ì§€ê³  ìˆë˜ ì´ë¯¸ì§€ë³´ë‹¤ ë” ë§ì€ ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. 

## Dropout

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%206.png)

ëª¨ë¸ì˜ ê³„ì¸µë§ˆë‹¤ dropoutì„ ì ìš©ì‹œí‚¤ë©´ ë¬´ì‘ìœ„ë¡œ ë…¸ë“œë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•œë‹¤. 

```python
data_augmentation = tf.keras.Sequential(
    [
        layers.experimental.preprocessing.RandomFlip('horizontal',
                                                     input_shape=(img_height, img_width, 3)),
        layers.experimental.preprocessing.RandomFlip('vertical'),
        layers.experimental.preprocessing.RandomRotation(0.2),
        layers.experimental.preprocessing.RandomZoom(0.2)
    ]
)

# ìœ„ ì½”ë“œëŠ” ëª¨ë¸ì˜ ë¶€ì¡±í•œ ë°ì´í„° í‘œë³¸ì˜ ìˆ˜ë¥¼ ë³´ì¶©í•´ì£¼ê¸° ë•Œë¬¸ì— training lossë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤. 

```

í•´ë‹¹ ê³¼ì •ì„ ê±°ì¹œ ì´í›„ ëª¨ë¸ì˜ ì„±ëŠ¥ ê³¡ì„ ì´ë‹¤. 

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%207.png)

ê³¼ì í•©ì´ í•´ê²°ëœ ëª¨ìŠµì´ê³  ê¸°ì¡´ ëª¨ë¸ì— ë¹„í•´ traiing ëª¨ë¸ì˜ ì •í™•ë„ì™€ Validation ëª¨ë¸ ì •í™•ë„ì˜ ì°¨ì´ê°€ í¬ê²Œ ì¤„ì–´ë“¤ì—ˆë‹¤. ê·¸ë¦¬ê³  loss ê·¸ë˜í”„ì— training lossì™€ validation lossì˜ ì°¨ì´ì¸ generalization gapì´ ì¤„ì–´ë“¤ì–´ ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ë‚˜ ì •í™•ë„ ì¸¡ë©´ì—ì„œ ëª¨ë‘ ê°œì„ ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. 

# ìµœì¢… ëª¨ë¸ êµ¬ì„±

ìµœì¢… ëª¨ë¸ì— ëŒ€í•œ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. 

```python
data_augmentation = tf.keras.Sequential(
    [
        layers.experimental.preprocessing.RandomFlip('horizontal',
                                                     input_shape=(img_height, img_width, 3)),
        layers.experimental.preprocessing.RandomFlip('vertical'),
        layers.experimental.preprocessing.RandomRotation(0.2),
        layers.experimental.preprocessing.RandomZoom(0.2)
    ]
)

model = Sequential([
    data_augmentation,
    layers.experimental.preprocessing.Rescaling(1. / 255),
    layers.Conv2D(16, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])

model.summary()

epochs = 20
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

tf.saved_model.save(model, 'C:\\Users\\jeong\\Desktop\\ì •ë¯¼\\3í•™ë…„ 2í•™ê¸°\\[DKU]ë”¥ëŸ¬ë‹_í´ë¼ìš°ë“œ\\final\\model')
```

![Untitled](%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A1%E1%84%8B%E1%85%AE%E1%84%83%E1%85%B3%20%E1%84%80%E1%85%B5%E1%84%86%E1%85%A1%E1%86%AF%E1%84%80%E1%85%AA%E1%84%8C%E1%85%A6%20-%20%E1%84%89%E1%85%A1%E1%84%8C%E1%85%B5%E1%86%AB%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%20%E1%84%87%E1%85%AE%E1%86%AB%E1%84%85%E1%85%B2%E1%84%92%E1%85%A1%20f2c9ba12b25e4046aab2669107a8099e/Untitled%208.png)

# ì „ì²´ ì†ŒìŠ¤ì½”ë“œ

```python
"""
    ë”¥ëŸ¬ë‹/í´ë¼ìš°ë“œ ê¸°ë§ ê³¼ì œ
    32170939 ê¹€ì •ë¯¼
    jeongmin981@gmail.com

    ì°¸ê³ ìë£Œ
    tensorflow.org

"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
import PIL

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

from pathlib import Path

# tf random seed
tf.random.set_seed(123)
# os.environ['TF_CPP_MIN_LOG_LEVEL'] ='3'

# dataset í´ë”ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸° ì „ ì‚¬ì§„ ì´ë¦„ì— ë”°ë¼ í´ë”ë³„ë¡œ ì •ë¦¬.
"""
    dataset/
        cloudy/
        rain/
        shine/
        sunrise/
        
"""

data_dir = Path('DeepLearning_Cloud/final/dataset2')
data_dir = Path('C:\\Users\\jeong\\PycharmProjects\\ML_algorithm\\DeepLearning_Cloud/final/dataset2')

image_list = list(data_dir.glob('*/*'))
print('ì´ë¯¸ì§€ì˜ ê°œìˆ˜ : {}'.format(len(image_list)))

# batch_size ì²˜ìŒì€ 32ë¡œ ì •í•¨
batch_size = 32
img_height = 180
img_width = 180

# Data_dirì— ìˆëŠ” ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ tf.data.datasetìœ¼ë¡œ í˜•ì„±
train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    batch_size=batch_size,
    image_size=(img_height,img_width),
    seed=123,
    validation_split=0.3,
    subset='training',
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    batch_size=batch_size,
    image_size=(img_height,img_width),
    seed=123,
    validation_split=0.3,
    subset='validation',
)

class_names = train_ds.class_names
print(class_names)

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i+1)
        plt.imshow(images[i].numpy().astype('uint8'))
        idx = 0
        for j in range(len(labels[i])):
            idx += j * labels[i][j]
        idx = idx.numpy().astype('uint8')
        plt.title(class_names[idx])
        plt.axis('off')
plt.show()

for image_batch, labels_batch in train_ds:
    print(image_batch.shape)
    print(labels_batch.shape)
    break

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)

normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixels values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))

num_classes = 4

# ì´ˆê¸° ëª¨ë¸
model = Sequential([
    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
    layers.Conv2D(16, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])
""" 
    from_logits íŒŒë¼ë¯¸í„°ëŠ” ë³´í†µ Trueìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì„ compileí•œë‹¤. ë§Œì•½ output_layersê°€ í™œì„±í•¨ìˆ˜ softmaxë¥¼ ê±°ì¹˜ì§€ ì•ŠëŠ”
    ê²½ìš° ì„¤ì •í•œë‹¤. 
    í•˜ì§€ë§Œ ì´ ëª¨ë¸ì— ê²½ìš° softmax í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— Falseë¡œ ì§€ì •í•´ì¤€ë‹¤. 
"""
model.summary()

epochs=20
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs,
    verbose=1
)

# model ì„±ëŠ¥ í‰ê°€
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

## validation dataì—ì„œ lossê°’ì´ ë”ì´ìƒ ì¤„ì§€ì•ŠëŠ” ê³¼ëŒ€ì í•©í˜„ìƒì´ë°œìƒ
## ì´ë¥¼ í•´ê²°í•˜ê¸°ìœ„í•´ ë°ì´í„°ì¦ê°•(Data Augumentation) ì‚¬ìš©

data_augmentation = tf.keras.Sequential(
    [
        layers.experimental.preprocessing.RandomFlip('horizontal',
                                                     input_shape=(img_height, img_width, 3)),
        layers.experimental.preprocessing.RandomFlip('vertical'),
        layers.experimental.preprocessing.RandomRotation(0.2),
        layers.experimental.preprocessing.RandomZoom(0.2)
    ]
)

plt.figure(figsize=(10,10))
for images, _ in train_ds.take(1):
    for i in range(9):
        augmented_images = data_augmentation(images)
        ax = plt.subplot(3, 3, i+1)
        plt.imshow(augmented_images[0].numpy().astype('uint8'))
        plt.axis("off")
plt.show()

model = Sequential([
    data_augmentation,
    layers.experimental.preprocessing.Rescaling(1. / 255),
    layers.Conv2D(16, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, (3,3), padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Dropout(0.2),
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
              metrics=['accuracy'])

model.summary()

epochs = 20
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

tf.saved_model.save(model, 'C:\\Users\\jeong\\Desktop\\ì •ë¯¼\\3í•™ë…„ 2í•™ê¸°\\[DKU]ë”¥ëŸ¬ë‹_í´ë¼ìš°ë“œ\\final\\model')
```